{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ebcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "path = \"/Users/janelameski/Desktop/jane/Thesis/point_clouds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f290dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the files in path\n",
    "file_list = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_list.append(os.path.join(path, file))\n",
    "        \n",
    "file_list = sorted(file_list)\n",
    "target_files = [a for a in file_list if \"target\" in a]\n",
    "source_files = [a for a in file_list if \"source\" in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c430164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.loadtxt(path+\"0A0602_source.txt\")\n",
    "file2 = np.loadtxt(path+\"0A0602_target.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d16ab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudsDataset(Dataset):\n",
    "    \"\"\"Point clouds dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (string): Path to the pointclouds.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = path\n",
    "        self.file_list = []\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".txt\"):\n",
    "                file_list.append(os.path.join(path, file))\n",
    "        self.target_files = [a for a in self.file_list if \"target\" in a]\n",
    "        self.source_files = [a for a in self.file_list if \"source\" in a]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52db4996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loader\n",
    "class DatasetLoader():\n",
    "    def __init__(self, root=path, npoints=4096):\n",
    "        self.npoints = npoints\n",
    "        self.root = root\n",
    "        self.sourcepath = sorted(glob.glob(os.path.join(self.root, '*source.txt')))\n",
    "        self.targetpath = sorted(glob.glob(os.path.join(self.root, '*target.txt')))\n",
    "       \n",
    "        self.cache = {}\n",
    "        self.cache_size = 30000\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(self.getSourceTargetPath(index))\n",
    "        if index in self.cache:\n",
    "            source, target = self.cache[index]\n",
    "        else:\n",
    "            s = self.sourcepath[index]\n",
    "            t = self.targetpath[index]\n",
    "#             print(s, t)\n",
    "            source = np.loadtxt(s)\n",
    "            target = np.loadtxt(t)\n",
    "\n",
    "            if len(self.cache) < self.cache_size:\n",
    "                self.cache[index] = (source,target)\n",
    "\n",
    "\n",
    "        n1 = source.shape[0]\n",
    "        sample_idx1 = np.random.choice(n1, self.npoints, replace=False)\n",
    "        n2 = target.shape[0]\n",
    "        sample_idx2 = np.random.choice(n2, self.npoints, replace=False)\n",
    "\n",
    "        source_ = np.copy(source[sample_idx1, :])\n",
    "        target_ = np.copy(target[sample_idx2, :])\n",
    "\n",
    "        return source_, target_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sourcepath)\n",
    "    \n",
    "    def getSourceTargetPath(self, index):\n",
    "        return (self.sourcepath[index], self.targetpath[index])\n",
    "        \n",
    "\n",
    "def plot_pcs(pc1, pc2):\n",
    "    print(pc1.shape)\n",
    "    print(pc2.shape)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(pc1[:,0], pc1[:,1], pc1[:,2], c='r', marker='o')\n",
    "    ax.scatter(pc2[:,0], pc2[:,1], pc2[:,2], c='b', marker='^')\n",
    "\n",
    "# d = DatasetLoader()\n",
    "\n",
    "# for i in range(5):\n",
    "#     pc1, pc2, = d[i]\n",
    "#     plot_pcs(pc1,pc2)\n",
    "#     break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec4cb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b9bf1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing data loader\n",
    "######################################\n",
    "# training_set = DatasetLoader()\n",
    "# training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "# for epoch in range(4):\n",
    "#     for source, target in training_generator:\n",
    "#         print(source.shape)\n",
    "#######################################        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f3a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
